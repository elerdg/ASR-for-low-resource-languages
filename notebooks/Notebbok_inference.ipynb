{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHHGYl4Tq8aQ"
      },
      "source": [
        "# Run inference on the fine-tuned model \n",
        "\n",
        "Test the ability of your fine-tuned model to make predictions on the test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XvLb-KDtpLNB"
      },
      "outputs": [],
      "source": [
        "%%capture \n",
        "!pip install datasets==2.4.0\n",
        "!pip install transformers==4.18 \n",
        "!pip install huggingface_hub==0.5.1 \n",
        "!pip install torchaudio==0.11  \n",
        "!pip install librosa \n",
        "!pip install jiwer   \n",
        "!git config --global credential.helper store \n",
        "!apt install git-lfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!huggingface-cli login  # login to huggingface to get the auth_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Iir1ssiimdYN"
      },
      "outputs": [],
      "source": [
        "%%capture  \n",
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "import json\n",
        "from IPython.display import display, HTML\n",
        "from transformers import Wav2Vec2ForCTC\n",
        "from transformers import Wav2Vec2CTCTokenizer\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, List, Optional, Union\n",
        "from transformers import AutoModelForCTC, Wav2Vec2Processor\n",
        "from datasets.utils.version import Version\n",
        "from datasets import load_dataset, load_metric, Audio\n",
        "import os\n",
        "import numpy as np\n",
        "import sys\n",
        "import warnings\n",
        "import argparse\n",
        "from torch import Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dJOjMgp3q1kn"
      },
      "outputs": [],
      "source": [
        "lang = \"it\"                   ## language code       \n",
        "corpus = 6.1                  ## the number of the corpus of the language\n",
        "test_pct = 20                 ## the percentange of the test set  \n",
        "model_dir = \"wav2vec2-large-xls-r-300m-it-100\"    ## model directory \n",
        "n_checkpoint = 23700               ## last checkpoint\n",
        "tokenizer_name = \"tokenizer_it\"    ## the tokenizer of the language "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc9b8f8trQtv"
      },
      "source": [
        "## Load :\n",
        "- the fine-tuned model\n",
        "- the tokenizer \n",
        "- the processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkh-hHX-q1ip"
      },
      "outputs": [],
      "source": [
        "\"\"\"import the model, processor, tokenizer\"\"\"\n",
        "print(\"loading saved model\")\n",
        "saved_model = AutoModelForCTC.from_pretrained(f\"./{model_dir}/checkpoint-{n_checkpoint}/\", local_files_only = True)\n",
        "saved_model.to(\"cuda\")\n",
        "print(\"loading tokenizer\")\n",
        "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(f\"./{tokenizer_name}/\", local_files_only = True)\n",
        "print(\"loading processor\")\n",
        "processor = Wav2Vec2Processor.from_pretrained(f\"./{model_dir}/checkpoint-{n_checkpoint}/\", local_files_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtiCHow0rPYx"
      },
      "source": [
        "## Load the test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtF9ul4Nq1go"
      },
      "outputs": [],
      "source": [
        "if corpus == 6.1 : \n",
        "    data_test = load_dataset(\"common_voice\", lang, split=f\"test[:{test_pct}%]\")\n",
        "    data_test = data_test.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"segment\", \"up_votes\"])\n",
        "else: \n",
        "    data_test = load_dataset(f\"mozilla-foundation/common_voice_{corpus}_0/\", lang, split=f\"test[:{test_pct}%]\", use_auth_token=True)    \n",
        "    data_test = data_test.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"segment\", \"up_votes\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avxHGqrKr1Mq"
      },
      "source": [
        "## Data pre-processing \n",
        "pre-process the data (transcriptions and speech signals) as it was done befor fine-tuning the model \n",
        "\n",
        "For the **transcriptions**: \n",
        "- remove punctuation \n",
        "- lowercase\n",
        "- substitute characters (if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIxYaDigq1eY"
      },
      "outputs": [],
      "source": [
        "print(\"preprocess data\") \n",
        "if lang == \"ar\":\n",
        "    chars_to_remove_regex = '[\\—\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\�\\°\\(\\)\\–\\…\\¿\\¡\\,\\\"\"\\‘\\”\\჻\\~\\՞\\؟\\،\\,\\॥\\«\\»\\„\\,\\“\\”\\「\\」\\‘\\’\\《\\》\\[\\]\\{\\}\\=\\`\\_\\+\\<\\>\\‹\\›\\©\\®\\→\\。\\、\\﹂\\﹁\\～\\﹏\\，\\【\\】\\‥\\〽\\『\\』\\〝\\⟨\\⟩\\〜\\♪\\؛\\/\\\\\\−\\^\\'\\ʻ\\ˆ\\´\\ʾ\\‧\\〟\\'ً \\'ٌ\\'ُ\\'ِ\\'ّ\\'ْ]'\n",
        "else:\n",
        "    chars_to_remove_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�\\°\\(\\)\\–\\…\\\\\\[\\]\\«\\»\\\\\\/\\^\\<\\>\\~\\_\\-\\¿\\¡\\—]'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JCFE20Oq1b5"
      },
      "outputs": [],
      "source": [
        "def remove_special_characters(batch):\n",
        "    batch[\"sentence\"] = re.sub(chars_to_remove_regex, '', batch[\"sentence\"]).lower()\n",
        "    return batch\n",
        "data_test = data_test.map(remove_special_characters)\n",
        "\n",
        "def replace_hatted_characters(batch):\n",
        "    batch[\"sentence\"] = re.sub('[’]', \"'\", batch[\"sentence\"])\n",
        "\n",
        "    return batch\n",
        "\n",
        "data_test= data_test.map(replace_hatted_characters)\n",
        "data_test = data_test.cast_column(\"audio\", Audio(sampling_rate=16_000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTVni4asJ_Qk"
      },
      "source": [
        "## Prepare the data for the model\n",
        "- transform input data into batches \n",
        "- filter the data setting a treashold (if not comment the line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RC25ogqq1Wf"
      },
      "outputs": [],
      "source": [
        "\"\"\"Prepare Dataset\"\"\"\n",
        "print(\"prepare dataset\")\n",
        "def prepare_dataset(batch):\n",
        "    audio = batch[\"audio\"]    \n",
        "    batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
        "    batch[\"input_length\"] = len(batch[\"input_values\"])\n",
        "    with processor.as_target_processor():\n",
        "        batch[\"labels\"] = processor(batch[\"sentence\"]).input_ids\n",
        "    return batch\n",
        "\n",
        "common_voice_test = data_test.map(prepare_dataset, remove_columns=data_test.column_names , keep_in_memory=True)\n",
        "common_voice_test= common_voice_test.filter(lambda x : x < 5.0*16000, input_columns=[\"input_length\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S1pg21xsJ6I"
      },
      "source": [
        "if you filtered the input data by length remember to filter also the original file whose transcriptions will be used as ground truth  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HeWenM2q1NZ"
      },
      "outputs": [],
      "source": [
        "print(\"loading reference transcriptions\")\n",
        "transcription = data_test\n",
        "transcription=[ el for el in data_test if len(el[\"audio\"][\"array\"]) < 5.0*16000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLFB6HGkQnd-"
      },
      "source": [
        "## Evaluation \n",
        "- input the batches into the model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWl3HlZNQlIM"
      },
      "outputs": [],
      "source": [
        "print('evaluation')\n",
        "predictions = [ ]\n",
        "for el in common_voice_test[\"input_values\"]:\n",
        "    input_dict = processor(el, return_tensors=\"pt\", padding=True)\n",
        "    logits= saved_model(input_dict.input_values.cuda()).logits\n",
        "    #print(logits.shape)\n",
        "    pred_ids = torch.argmax(logits[0], dim=-1)\n",
        "    #print(pred_ids)\n",
        "    predicted_sentences = processor.decode(pred_ids)\n",
        "    predictions.append(predicted_sentences)\n",
        "    #print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrwkmavTZgaa"
      },
      "source": [
        "<a name=\"s2\"></a> \n",
        "## Calculate CER and WER\n",
        "- load the metrics CER and WER\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjVGyFEqt7-A"
      },
      "outputs": [],
      "source": [
        "wer = load_metric(\"wer\")\n",
        "cer = load_metric(\"cer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ahX7faQu7yw"
      },
      "source": [
        "\n",
        "- pass the predictions to the metrics: \n",
        "  - **CER**: takes the **string of characters from the predictions**, and the **string of characters of the reference sentence**. \n",
        "  - **WER**: takes the **list of words from the reference sentence** and the **list of words from the predicted sentence**. \n",
        "- the predicted sentences and the original transcriptions are combined into a dataframe and save into a csv file  (if data is too big comment this part) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tofg9I3Otcwb"
      },
      "outputs": [],
      "source": [
        "list_sent=[]\n",
        "list_ref=[]\n",
        "\n",
        "for i, sentence_ in enumerate(predictions):\n",
        "    print(i, \"Sentence: \",  sentence_)\n",
        "    print(\"Reference: \",  transcription[i][\"sentence\"])\n",
        "    list_sent.append(sentence_)\n",
        "    list_ref.append(transcription[i][\"sentence\"])\n",
        "    #wer_DSI(sentence_ , transcription[i][\"sentence\"], debug=True)  ## uncomment to print Deletions, Substitutions, Insertions\n",
        "\n",
        "result_cer= cer.compute(predictions=[\" \".join(list_sent)], references=[\" \".join(list_ref)] )\n",
        "print(\"CER\", result_cer)\n",
        "\n",
        "result_wer= wer.compute(predictions=[list_sent], references=[list_ref])\n",
        "print(\"WER: \", result_wer)\n",
        "\n",
        "d={ \"predictions\":list_sent, \"references\":list_ref }\n",
        "df = pd.DataFrame(d)\n",
        "df.to_csv(f\"./INFERENCE_{lang}-{model_dir}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3UMwLsjOPPL"
      },
      "source": [
        "#### Function to print Deletions, Substitutions, and Insertions \n",
        "\n",
        "to use this function from [Pyzone](https://pyzone.dev/word-error-rate-in-python/) you can uncomment the line in the code above, or you can used it on the sentences saved in the CSV file "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IkPPdUNN65d"
      },
      "outputs": [],
      "source": [
        "def wer_DSI(ref, hyp ,debug=False):\n",
        "    r = ref.split()\n",
        "    h = hyp.split()\n",
        "    #costs will holds the costs, like in the Levenshtein distance algorithm\n",
        "    costs = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
        "    # backtrace will hold the operations we've done.\n",
        "    # so we could later backtrace, like the WER algorithm requires us to.\n",
        "    backtrace = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
        "\n",
        "    OP_OK = 0\n",
        "    OP_SUB = 1\n",
        "    OP_INS = 2\n",
        "    OP_DEL = 3\n",
        "\n",
        "    DEL_PENALTY=1 # Tact\n",
        "    INS_PENALTY=1 # Tact\n",
        "    SUB_PENALTY=1 # Tact\n",
        "\n",
        "    # First column represents the case where we achieve zero\n",
        "    # hypothesis words by deleting all reference words.\n",
        "    for i in range(1, len(r)+1):\n",
        "        costs[i][0] = DEL_PENALTY*i\n",
        "        backtrace[i][0] = OP_DEL\n",
        "\n",
        "    # First row represents the case where we achieve the hypothesis\n",
        "    # by inserting all hypothesis words into a zero-length reference.\n",
        "    for j in range(1, len(h) + 1):\n",
        "        costs[0][j] = INS_PENALTY * j\n",
        "        backtrace[0][j] = OP_INS\n",
        "\n",
        "    # computation\n",
        "    for i in range(1, len(r)+1):\n",
        "        for j in range(1, len(h)+1):\n",
        "            if r[i-1] == h[j-1]:\n",
        "                costs[i][j] = costs[i-1][j-1]\n",
        "                backtrace[i][j] = OP_OK\n",
        "            else:\n",
        "                substitutionCost = costs[i-1][j-1] + SUB_PENALTY # penalty is always 1\n",
        "                insertionCost    = costs[i][j-1] + INS_PENALTY   # penalty is always 1\n",
        "                deletionCost     = costs[i-1][j] + DEL_PENALTY   # penalty is always 1\n",
        "\n",
        "                costs[i][j] = min(substitutionCost, insertionCost, deletionCost)\n",
        "                if costs[i][j] == substitutionCost:\n",
        "                    backtrace[i][j] = OP_SUB\n",
        "                elif costs[i][j] == insertionCost:\n",
        "                    backtrace[i][j] = OP_INS\n",
        "                else:\n",
        "                    backtrace[i][j] = OP_DEL\n",
        "\n",
        "    # back trace though the best route:\n",
        "    i = len(r)\n",
        "    j = len(h)\n",
        "    numSub = 0\n",
        "    numDel = 0\n",
        "    numIns = 0\n",
        "    numCor = 0\n",
        "    n_sub=[]\n",
        "\n",
        "    if debug:\n",
        "        print(\"OP\\tREF\\tHYP\")\n",
        "        lines = []\n",
        "    while i > 0 or j > 0:\n",
        "        if backtrace[i][j] == OP_OK:\n",
        "            numCor += 1\n",
        "            i-=1\n",
        "            j-=1\n",
        "            if debug:\n",
        "                lines.append(\"OK\\t\" + r[i]+\"\\t\"+h[j])\n",
        "        elif backtrace[i][j] == OP_SUB:\n",
        "            numSub +=1\n",
        "            i-=1\n",
        "            j-=1\n",
        "            if debug:\n",
        "                lines.append(\"SUB\\t\" + r[i]+\"\\t\"+h[j])\n",
        "        elif backtrace[i][j] == OP_INS:\n",
        "            numIns += 1\n",
        "            j-=1\n",
        "            if debug:\n",
        "                lines.append(\"INS\\t\" + \"****\" + \"\\t\" + h[j])\n",
        "        elif backtrace[i][j] == OP_DEL:\n",
        "            numDel += 1\n",
        "            i-=1\n",
        "            if debug:\n",
        "                lines.append(\"DEL\\t\" + r[i]+\"\\t\"+\"****\")\n",
        "    if debug:\n",
        "        lines = reversed(lines)\n",
        "        for line in lines:\n",
        "            print(line)\n",
        "        print(\"Ncor \" + str(numCor))\n",
        "        print(\"Nsub \" + str(numSub))\n",
        "        print(\"Ndel \" + str(numDel))\n",
        "        print(\"Nins \" + str(numIns))\n",
        "        \n",
        "    #return (numSub + numDel + numIns) / (float) (len(r))\n",
        "    wer_result = round( (numSub + numDel + numIns) / (float) (len(r)), 3)\n",
        "    return {'WER':wer_result, 'Cor':numCor, 'Sub':numSub, 'Ins':numIns, 'Del':numDel}\n",
        "    #return numSub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a089fX3ESR33"
      },
      "outputs": [],
      "source": [
        "## load the entences from saved csv file \n",
        "\n",
        "your_path = f\"./INFERENCE_{lang}-{model_dir}.csv\"\n",
        "inference_file = pd.read_csv(your_path, sep=\",\")\n",
        "\n",
        "for i, sentence_ in enumerate(inference_file[\"references\"]):\n",
        "  x = wer(sentence_ , inference_file[\"predictions\"][i], debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrEIypiHNXGt"
      },
      "source": [
        "# Run inference with a Language Model: \n",
        "\n",
        "Without a language model the output of the fine-tuned model is just the concatenation of predicted characters, and non-existing words could be predicted. To improve the predictions and rescore the error rates, a 5-gram language model can be applied to decode the output of the fine-tuned model. \n",
        "\n",
        "Following this [tutorial by Von Platen (2022)](https://huggingface.co/blog/wav2vec2-with-ngram) you can train a 5-gram model on texts of your target langauge. \n",
        "\n",
        "To apply the n-gram language model follow this steps **after the data have been processed**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ5znn3pNxNE"
      },
      "source": [
        "\n",
        "\n",
        "### Create a vocabulary from the tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stS9LLiyPzJN"
      },
      "outputs": [],
      "source": [
        "print(\"create the vocab from tokenizer\")\n",
        "vocab_dict = processor.tokenizer.get_vocab()\n",
        "sorted_vocab_dict = {k.lower(): v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}\n",
        "print(vocab_dict)\n",
        "print(sorted_vocab_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa5T1la1P5wL"
      },
      "source": [
        "### Create a decoder for the langauge model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YANtmBLP0eO"
      },
      "outputs": [],
      "source": [
        "print(\"create a decoder for the language model\")\n",
        "from pyctcdecode import build_ctcdecoder\n",
        "\n",
        "decoder = build_ctcdecoder(labels=list(sorted_vocab_dict.keys()),\n",
        "                           kenlm_model_path=\"./5gram_correct.arpa\",)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0SlwP9tYe50"
      },
      "source": [
        "### Create the \"new\" processor "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjpWtFcfYc-a"
      },
      "outputs": [],
      "source": [
        "print(\"create the processor with the language model\")\n",
        "from transformers import Wav2Vec2ProcessorWithLM\n",
        "processor_with_lm = Wav2Vec2ProcessorWithLM(\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    decoder=decoder\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBJaX_PZWqCP"
      },
      "source": [
        "### Run the Evaluation \n",
        "this time we don't apply argmax to the logits \n",
        "and the processor will be the **processor_with_lm** just created above\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QKjNi2NPYKL"
      },
      "outputs": [],
      "source": [
        "print(\"\"\"evaluation\"\"\")\n",
        "\n",
        "predictions=[]\n",
        "for el in common_voice_test[\"input_values\"]:\n",
        "    input_dict = processor_with_lm(el, return_tensors=\"pt\", padding=True)\n",
        "    logits= saved_model(input_dict.input_values.cuda()).logits\n",
        "    #print(logits.shape)\n",
        "    transcription = processor_with_lm.batch_decode(logits.detach().cpu().numpy()).text\n",
        "    #print(transcription)\n",
        "    predictions.append(transcription[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxgsy63aYsjq"
      },
      "source": [
        "After, compute the CER and WER as done [above](#s2)  \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Notebbok-inference.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "798f8bd8462e6e84dd41cd87116bcc26a01eb9f28067e4207fedcdb329b1b144"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
